{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization \n",
    "\n",
    "## TODO: k-NN + directed version (direction = style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"070debb4-7cf5-453d-9156-852af0d48165\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"070debb4-7cf5-453d-9156-852af0d48165\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"070debb4-7cf5-453d-9156-852af0d48165\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '070debb4-7cf5-453d-9156-852af0d48165' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"070debb4-7cf5-453d-9156-852af0d48165\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"070debb4-7cf5-453d-9156-852af0d48165\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_dim : 16\n",
      "sequence_max : 30\n",
      "decoder_num_layers : 2\n",
      "beta_period : 500\n",
      "training_dir : logs/no_char2word\n",
      "epoches : 10000\n",
      "batch_size : 600\n",
      "char2word_num_layers : 2\n",
      "initialize : False\n",
      "teacher_forcing : True\n",
      "learning_rate_change_rate : 3000\n",
      "beta_offset : 15\n",
      "encoder_num_layers : 2\n",
      "char2word_state_size : 256\n",
      "sequence_min : 8\n",
      "use_char2word : False\n",
      "dtype_precision : 32\n",
      "cell : GRU\n",
      "use_sentiment_feature : False\n",
      "initial_learning_rate : 0.001\n",
      "decoder_state_size : 1024\n",
      "output_keep_prob : 0.5\n",
      "acceptable_accuracy : 0.4\n",
      "peephole : True\n",
      "input_keep_prob : 0.9\n",
      "encoder_state_size : 1024\n",
      "latent_loss_weight : 0.01\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "output_notebook()\n",
    "\n",
    "import data_utils_LMR\n",
    "from data_utils_LMR import prepare_data,read_data, EncoderDecoder\n",
    "from model import Vrae as Vrae_model\n",
    "from batch import Generator\n",
    "\n",
    "training_dir = 'logs/'\n",
    "training_dir += 'no_char2word'\n",
    "\n",
    "# sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentimentAnalyzer = SentimentIntensityAnalyzer()\n",
    "def getSentimentScore(sentence):\n",
    "    scores = sentimentAnalyzer.polarity_scores(sentence)\n",
    "    return (scores['neg'], scores['neu'] ,scores['pos'])\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "def string2bool(st):\n",
    "    if st.lower() == \"true\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "with open(training_dir +'/flags.json', 'r') as fp:\n",
    "    FLAGS = dotdict(json.loads( fp.read() ) )\n",
    "    \n",
    "for k,v in FLAGS.iteritems():\n",
    "    print k,':',v\n",
    "      \n",
    "n_samples = 5000#int(FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reading data line 10000\n",
      "  reading data line 20000\n",
      "  reading data line 30000\n",
      "  reading data line 40000\n",
      "  reading data line 50000\n",
      "  reading data line 60000\n",
      "  reading data line 70000\n",
      "77977  sentences\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/cWyKYVBecsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48fcb47e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(training_dir +'/training_parameters.json', 'r') as fp:\n",
    "    training_parameters = json.loads( fp.read() )\n",
    "# vocabulary encoder-decoder\n",
    "encoderDecoder = EncoderDecoder()\n",
    "num_symbols = encoderDecoder.vocabularySize()\n",
    "#prepare_data(1000)\n",
    "sentences, ratings = read_data( max_size=None, \n",
    "                               max_sentence_size=training_parameters['seq_max'],\n",
    "                               min_sentence_size=int(FLAGS.sequence_min), \n",
    "                               test=False) \n",
    "print len(sentences), \" sentences\"\n",
    "if len(sentences) < n_samples:\n",
    "    n_samples = len(sentences) - 1\n",
    "sns.distplot( [len(sent) for sent in sentences])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "space_symbol = encoderDecoder.encode(\"I am\")[1]\n",
    "word_delimiters = [ data_utils_LMR._EOS, data_utils_LMR._GO, space_symbol ]\n",
    "batch_gen = Generator(sentences, ratings, n_samples, word_delimiters)\n",
    "num_iters = FLAGS.epoches * batch_gen.iterations_per_epoch()\n",
    "# text decoder ( text <-> ids)\n",
    "encoderDecoder = EncoderDecoder()\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}, # do not use GPU for testing\n",
    "    )\n",
    "\n",
    "# load model\n",
    "vrae_model = Vrae_model(char2word_state_size = int(FLAGS.char2word_state_size), \n",
    "                     char2word_num_layers = int(FLAGS.char2word_num_layers), \n",
    "                     encoder_state_size = int(FLAGS.encoder_state_size), \n",
    "                     encoder_num_layers = int(FLAGS.encoder_num_layers), \n",
    "                     decoder_state_size = int(FLAGS.decoder_state_size), \n",
    "                     decoder_num_layers = int(FLAGS.decoder_num_layers), \n",
    "                          latent_dim=int(FLAGS.latent_dim),\n",
    "                         batch_size=n_samples,\n",
    "                         num_symbols=num_symbols,\n",
    "                        latent_loss_weight=float(FLAGS.latent_loss_weight),\n",
    "                         dtype_precision=FLAGS.dtype_precision,\n",
    "                        cell_type=FLAGS.cell, \n",
    "                        peephole=FLAGS.peephole,\n",
    "                        input_keep_prob=float(FLAGS.input_keep_prob),\n",
    "                        output_keep_prob=float(FLAGS.output_keep_prob),\n",
    "                      sentiment_feature = string2bool(FLAGS.use_sentiment_feature),\n",
    "                      use_char2word = string2bool(FLAGS.use_char2word) \n",
    "                       )\n",
    "\n",
    "def zToXdecoded(session,z_sample,s_length):\n",
    "    x_reconstruct = vrae_model.zToX(session,z_sample,s_length)\n",
    "    return encoderDecoder.prettyDecode( np.argmax(x_reconstruct[0], axis= 1) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/no_char2word/model.ckp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/no_char2word/model.ckp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "#print train_dir\n",
    "np.random.seed(13)\n",
    "batch_gen.shuffle()\n",
    "samples = []\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    padded_batch_xs, batch_ys, batch_lengths, batch_weights, end_of_words, batch_word_lengths, max_length  = batch_gen.next_batch()\n",
    "    vaderSentiments = [ getSentimentScore(encoderDecoder.prettyDecode(xx)) for xx in padded_batch_xs]\n",
    "    x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val, losses  = vrae_model.reconstruct( sess, \n",
    "                                                                                         padded_batch_xs,batch_lengths, \n",
    "                                                                                         batch_weights, \n",
    "                                                                                         end_of_words, \n",
    "                                                                                         batch_word_lengths,\n",
    "                                                                                        vaderSentiments)\n",
    "print \"Done!\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaderSentiments = [ getSentimentScore(encoderDecoder.prettyDecode(padded_batch_xs[i])) for i in xrange(n_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: (0.0, 1.0, 0.0) | rating: 3\n",
      "the premise might even work.\n",
      "the premise might even work.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 0.68, 0.32) | rating: 3\n",
      "some of the music is campy and fun.\n",
      "some of the music is campy and fun.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 0.46, 0.54) | rating: 1\n",
      "i' d better revise my defense policy!\n",
      "i' d better revise my eyes mentions.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 1.0, 0.0) | rating: 8\n",
      "it knows what the future holds.\n",
      "it sues,   at where should be.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 1.0, 0.0) | rating: 1\n",
      "but it was all about barbra.\n",
      "but it was all about barbra.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 0.606, 0.394) | rating: 2\n",
      "were the characters still alive?\n",
      "were the characters still alive?\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 0.2, 0.8) | rating: 8\n",
      "well worth watching.\n",
      "well worth watching.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 0.323, 0.677) | rating: 4\n",
      "oh well.\n",
      "oh well.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 1.0, 0.0) | rating: 9\n",
      "or is he just misguided by society?\n",
      "or, sime sisis is moni n ned maes.\n",
      "------------------------------------------\n",
      "sentiment: (0.0, 1.0, 0.0) | rating: 7\n",
      "they ran directly out of the apartment.\n",
      "they are minding somewhet for the fals.\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(13)\n",
    "for i in range(10):\n",
    "    i = int(np.random.random()*n_samples)\n",
    "    i = i\n",
    "    print \"sentiment:\", vaderSentiments[i],\"| rating:\", batch_ys[i]\n",
    "    print encoderDecoder.prettyDecode( padded_batch_xs[i] )\n",
    "    print encoderDecoder.prettyDecode( np.argmax(x_reconstruct[i], axis= 1) )\n",
    "    print \"------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction in the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dimension reduction\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array(z_vals)\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "zs_reduced = model.fit_transform(X) \n",
    "xs = [ zs_reduced[i,0] for i in xrange(n_samples) ]\n",
    "ys = [ zs_reduced[i,1] for i in xrange(n_samples) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.layouts import column\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Select\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "!export BOKEH_LOG_LEVEL=error\n",
    "output_file(\"latent_space.html\")\n",
    "\n",
    "inputs = [encoderDecoder.prettyDecode(x) for x in padded_batch_xs]\n",
    "M =max(batch_lengths)\n",
    "binary_rating = [ int(r > 5) for r in batch_ys]\n",
    "colors_sent = [ \"#%02x%02x%02x\" % ( 100 + 150 * r[0] ,  100 + 150 * r[2]  , 100 + 100 * r[1]  ) for r in vaderSentiments ]\n",
    "color_rating = [ \"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in binary_rating ]\n",
    "colors_lengths = [ \"#%02x%02x%02x\" % (  ( 255 * (float(r)/float(M))), 50, 255 - 255 * (float(r)/float(M)))  for r in batch_lengths ]\n",
    "hasQuestionMark = [ int(\"?\" in x) for x in inputs]\n",
    "colors_questionMark = [\"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in hasQuestionMark]\n",
    "is_past_voice = [ int(\"was\" in x) or int(\"were\" in x) or int(\"did\" in x) or int(\"had\" in x) for x in inputs]\n",
    "colors_past = [\"#%02x%02x%02x\" % (255 * (1-r) , 100, 255*r) for r in is_past_voice]\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=xs,\n",
    "            y=ys,\n",
    "            input=inputs,\n",
    "            output= [encoderDecoder.prettyDecode(np.argmax(y, axis= 1) ) for y in x_reconstruct],\n",
    "            rating=batch_ys,\n",
    "            sent= vaderSentiments,\n",
    "            rating_color=color_rating,\n",
    "            sentiment_color=colors_sent,\n",
    "            lenght_color=colors_lengths,\n",
    "            questionMark_color=colors_questionMark,\n",
    "            past_color = colors_past,\n",
    "            lengths=batch_lengths,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"index\", \"$index\"),\n",
    "            (\"(x,y)\", \"($x, $y)\"),\n",
    "            (\"input\", \"@input\"),\n",
    "            (\"output\", \"@output\"),\n",
    "            (\"rating\", \"@rating\"),\n",
    "            (\"lengths\", \"@lengths\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "p = figure(plot_width=800, plot_height=600, tools=[hover],title=\"Latent space\")\n",
    "cir = p.circle('x', 'y', size=9, source=source, fill_color=\"sentiment_color\", alpha=0.8)\n",
    "\n",
    "callback = CustomJS(args=dict(cir=cir,source=source), code=\"\"\"\n",
    "        var selected_color = cb_obj.value;\n",
    "        selected_color = selected_color\n",
    "        console.log(selected_color);\n",
    "        cir.glyph.line_color.field = selected_color;\n",
    "        cir.glyph.fill_color.field = selected_color;\n",
    "        source.trigger(\"change\")\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "select = Select(title=\"Color:\", value=\"sentiment\", options=[\"sentiment_color\", \"rating_color\", \"lenght_color\", \"questionMark_color\", \"past_color\"], callback=callback)\n",
    "\n",
    "\n",
    "layout = column(select, p)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cols = sns.color_palette()\n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "major_sent = np.argmax(vaderSentiments, axis = 1)\n",
    "for i in xrange(n_samples):\n",
    "    if major_sent[i] == 2:\n",
    "        pos.append( z_mean_val[i,:] )\n",
    "    elif major_sent[i] == 0:\n",
    "        neg.append( z_mean_val[i,:] )\n",
    "    else:\n",
    "        neu.append( z_mean_val[i,:] )\n",
    "\n",
    "print len(pos), \"positive sentences\"\n",
    "print len(neg), \"negative sentences\"\n",
    "print len(neu), \"neutral sentences\"\n",
    "\n",
    "pos = np.array(pos)\n",
    "neg = np.array(neg)\n",
    "neu = np.array(neu)\n",
    "\n",
    "side_lenght = int(np.sqrt(int(FLAGS.latent_dim)))\n",
    "if side_lenght**2 < int(FLAGS.latent_dim):\n",
    "    side_lenght +=1\n",
    "f, axs = plt.subplots(ncols=side_lenght, nrows=side_lenght, sharey=True, figsize=(10, 10))\n",
    "for i in xrange(side_lenght):\n",
    "    for j in xrange(side_lenght):\n",
    "        k = i*side_lenght+j\n",
    "        if k < int(FLAGS.latent_dim):\n",
    "            sns.distplot( neu[:,k], ax=axs[i,j], hist=False, color= cols[0] )\n",
    "            sns.distplot( pos[:,k], ax=axs[i,j], hist=False, color= cols[1] )\n",
    "            sns.distplot( neg[:,k], ax=axs[i,j], hist=False, color= cols[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sentiment Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import random\n",
    "\n",
    "KLs = []\n",
    "for k in xrange(int(FLAGS.latent_dim)):\n",
    "    a = list(neg[:,k])\n",
    "    b = list(pos[:,k])\n",
    "    kl = np.abs( np.mean(a) - np.mean(b))\n",
    "    \n",
    "    KLs.append( kl )\n",
    "\n",
    "sorted_kls = sorted( enumerate(KLs) , key = lambda x: x[1], reverse=True )\n",
    "for k,kl in sorted_kls:\n",
    "    print k,kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=sorted_kls[0][0]\n",
    "sns.distplot( neu[:,k], hist=False, color= cols[0] )\n",
    "sns.distplot( pos[:,k], hist=False, color= cols[1] )\n",
    "sns.distplot( neg[:,k], hist=False, color= cols[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks = sorted_kls[0][:3]\n",
    "dx = 2\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    u0 = \"I like this movie.\"\n",
    "    u1 = \"I recommend this movie.\"\n",
    "    u = u0\n",
    "    #print u\n",
    "    z0 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "    #z0 = np.zeros(int(FLAGS.latent_dim))\n",
    "    dz = np.zeros(int(FLAGS.latent_dim))\n",
    "    dz[k] = dx\n",
    "    z1 = z0 + dz\n",
    "    z2 = z0 - dz\n",
    "    print \"distance between two points:\",np.linalg.norm(z2-z1),\"\\n\"\n",
    "    zs = []\n",
    "    for t in np.linspace(0,1,30):\n",
    "        zs.append( (1-t) * z1 + t * z2 )\n",
    "\n",
    "    for z_ in zs:\n",
    "        print zToXdecoded(sess, z_ , 45 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension pairplot\n",
    "\n",
    "cross check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "major_sent = np.argmax(vaderSentiments, axis = 1)\n",
    "sent_df = pd.DataFrame( z_mean_val )\n",
    "sent_df['major_sent'] = major_sent\n",
    "#sns.pairplot(sent_df, hue='major_sent', diag_kind=\"kde\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous space: Homotopies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/no_char2word/model.ckp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/no_char2word/model.ckp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "distance between two points: 5.9449 \n",
      "\n",
      "i don' t recommend it to anyone.\n",
      "i won' t recommend it to avy de.\n",
      "i wan' t revoaved it bo mad i a.\n",
      "i want i to get me i aad d b.\n",
      "i want i to get meai a a ba .\n",
      "i want d to bet ivilgad a boobie.\n",
      "i want d to be iveided a bookie.\n",
      "i want i to be iveiled a bookie.\n",
      "i want it tover and loved a movie.\n",
      "i wan not giver a e b by a mover.\n",
      "i tan not really i dis betten mn.\n",
      "i think i really did net better.\n",
      "i think i really enjoyed it to me.\n",
      "it was bean and liaved by tomic.\n",
      "it was bean and leave  y homica.\n",
      "it was neat and latgr be  motie.\n",
      "it was neat and later bad movie!\n",
      "it was neat and leave a ooman it.\n",
      "it'as iear and leave a booai i.\n",
      "it'as really a very came movie.\n",
      "it' s really a neceneed book i.\n",
      "it' s really a ceeeed bad movie.\n",
      "it' s really a ceeeer bad movie.\n",
      "it' s really a ceented bod  ov.\n",
      "it' s really a reeated borb movie.\n",
      "it' s really a reaandle bombie.\n",
      "it' s really a veaandly boming.\n",
      "it' s really a very bad movie.\n",
      "it is  a really rare bed byd.\n",
      "this is a really bad eeelimamovie.\n",
      "this is a really bad realym movie.\n",
      "this is a really badlly bad movie.\n",
      "this is a really really bad movie.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    # show interpolations\n",
    "    u0 = [\"I loved it.\" , \"I hated this film.\"]\n",
    "    u01 = [\"I loved it.\" , \"It was terrible.\"]\n",
    "    u1 = [\"I loved this movie!.\", \"I hated this movie!\"]\n",
    "    u2 = [\"The best movie I've seen!\", \"The worst movie ever made.\"]\n",
    "    u3 = [\"great movie.\", \"terrible movie.\"]\n",
    "    u4 = [\"that's actually pretty good.\" , \"That was a failure.\"]\n",
    "    u5 = [\"I didn't laugh at all.\", \"I wanted to love this movie.\"]\n",
    "    u6 = [\"so bad that it's really bad\" , \"Where is the acting?\"]\n",
    "    u7 = [\"I love old movies.\", \"I prefer old movies.\"]\n",
    "    u8 = [\"the music is very bad.\", \"the music is just awful.\"]\n",
    "    u9 = [\"awesome!\", \"terrible.\"]\n",
    "    u10 = [\"awful.\" , \"pretty worthless.\"]\n",
    "    u11 = [\"yes you do.\" , \"no you don't.\"]\n",
    "    u12 = [\"The acting was really bad.\" , \"The acting was really good!\"]\n",
    "    u13 = [\"This film was fascinatingly stupid.\" , \"This is an excellent film.\"]\n",
    "    u14 = [\"I don't recommend it to anyone.\", \"This is a really really bad movie.\"]\n",
    "    u = u14\n",
    "    z1 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u[0]),sentiment=getSentimentScore(u[0]))[0]\n",
    "    z2 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u[1]),sentiment=getSentimentScore(u[1]))[0]\n",
    "    #z1 = np.zeros(16)\n",
    "    #z2 = 0.1 * np.ones(16)\n",
    "    print \"distance between two points:\",np.linalg.norm(z2-z1),\"\\n\"\n",
    "    zs = []\n",
    "    for t in np.linspace(0,1,50):\n",
    "        zs.append( (1-t) * z1 + t * z2 )\n",
    "    \n",
    "    sents = [zToXdecoded(sess, z_ , 45 ) for z_ in zs]\n",
    "    appeared = []\n",
    "    for x in sents:\n",
    "        if x not in appeared:\n",
    "            print x\n",
    "            appeared.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction: Reconstructing using Model's knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    u0 = \"I like this movie.\"\n",
    "    u1 = \"It was terrible.\"\n",
    "    u2 = \"I recommend it.\"\n",
    "    u3 = \"I loved it.\"\n",
    "    us = [u0,u1,u2,u3]\n",
    "    for u in us:\n",
    "        z = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "        print u, \"->\",\n",
    "        print zToXdecoded(sess,z,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    a = \"I liked it.\"\n",
    "    b = \"I didn't like it.\"\n",
    "    c = \"I recommend this movie.\"\n",
    "    \n",
    "    #a = \"I like it\"\n",
    "    #b = \"I liked it.\"\n",
    "    #c = \"I recommend it.\"\n",
    "    \n",
    "    #a = \"I love this movie!\"\n",
    "    #b = \"I like this movie.\"\n",
    "    #c = \"I love the acting!\"\n",
    "    \n",
    "    za = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(a), sentiment=getSentimentScore(a) )[0]\n",
    "    zb = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(b), sentiment=getSentimentScore(b))[0]\n",
    "    zc = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(c), sentiment=getSentimentScore(c))[0]\n",
    "    \n",
    "    # translation\n",
    "    zd = zc + (zb - za)\n",
    "    print \"a \\t\\t|\", a,\"|\", zToXdecoded(sess, za , 40 )\n",
    "    print \"bÂ \\t\\t|\", b,\"|\", zToXdecoded(sess, zb , 40 )\n",
    "    print \"c \\t\\t|\", c,\"|\", zToXdecoded(sess, zc , 40 )\n",
    "    print\n",
    "    print \"c + b-a \\t|\", zToXdecoded(sess, zd , 40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"./\"+training_dir+'/model.ckp')\n",
    "    print\n",
    "    \n",
    "    # show interpolations\n",
    "    u1 = \"That's actually pretty good.\"\n",
    "    u2 = \"I love it.\"\n",
    "    u = u1\n",
    "    z1 = vrae_model.XToz(sess, *encoderDecoder.encodeForTraining(u), sentiment=getSentimentScore(u))[0]\n",
    "    print z1\n",
    "    print\n",
    "    r = 1\n",
    "    zs = []\n",
    "    for t in range(50):\n",
    "        z2 = [ z_ + r * np.random.random() for z_ in z1  ]\n",
    "        zs.append( z2)\n",
    "\n",
    "    for z_ in zs:\n",
    "        print zToXdecoded(sess, z_ , 40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log p(x) =  \\sum_{i=1}^N q(z^{(i)} | x ) \\log p(x)$$\n",
    "\n",
    "\n",
    "$$ \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ] $$\n",
    "   \n",
    "   \n",
    "$$ \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) $$\n",
    "\n",
    "\n",
    "$$ D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-199-5662f678ed41>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-199-5662f678ed41>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    & = \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ]  \\   & = \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) \\   & = D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " & = \\sum_{i=1}^N q(z^{(i)} | x ) \\left [    \\frac{q_\\phi(z^{(i)} | x) p_\\theta(x,z)}{p_\\theta(z|x^{(i)}) q_\\phi(z^{(i)} | x) }    \\right ]  \\\\\n",
    "    & = \\sum_{i=1}^N q(z^{(i)} | x ) \\log \\frac{q(z^{(i)} | x )}{p_\\theta(z|x^{(i)})} + q(z^{(i)} | x ) \\log p_\\theta(x,z) - q(z^{(i)} | x ) log q(z^{(i)} | x ) \\\\\n",
    "    & = D_{KL} (q(z^{(i)} | x ) || p_\\theta(z|x^{(i)})) + E_{q(z^{(i)} | x )} [- \\log q(z^{(i)} | x ) + \\log p_\\theta (x,z)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L} (\\theta , \\phi ; \\theta^{(i)})  = E_{q_\\phi(z| x^{(i)} )} [- \\log q_\\phi( | x^{(i)} ) + \\log p_\\theta (x^{(i)},z)] $$\n",
    "\n",
    "$$- D_{KL} ( q_\\phi(z | x^{(i)} ) || p_\\theta(z) ) + E_{q_\\phi(z| x^{(i)} )} [Â \\log p_\\theta(x^{(i)} |Â z)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing more, nothing less.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "i still like dr.  &  0.0  &  0.444  &  0.556 \\\\ \\hline\n",
      "well, why else?  &  0.0  &  0.488  &  0.512 \\\\ \\hline\n",
      "this one is anything but.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "how can he pass that in the movie?  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "i love this movie!  &  0.0  &  0.308  &  0.692 \\\\ \\hline\n",
      "this movie delivers.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "this is a really, really bad movie.  &  0.449  &  0.551  &  0.0 \\\\ \\hline\n",
      "i just was not too impressed.  &  0.39  &  0.61  &  0.0 \\\\ \\hline\n",
      "i got a huge kick out of this movie.  &  0.0  &  0.723  &  0.277 \\\\ \\hline\n",
      "the dialog was bad.  &  0.538  &  0.462  &  0.0 \\\\ \\hline\n",
      "i give this film 0000 stars.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "its scary.  &  0.762  &  0.238  &  0.0 \\\\ \\hline\n",
      "this is the ultimate opposite of it.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
      "she' s a good actress.  &  0.0  &  0.408  &  0.592 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "vaderSentiments = [ getSentimentScore(encoderDecoder.prettyDecode(xx)) for xx in padded_batch_xs]\n",
    "for k in range(15):\n",
    "    k = int( np.random.random() * len(padded_batch_xs) )\n",
    "    t = encoderDecoder.prettyDecode(padded_batch_xs[k]) \n",
    "    s = getSentimentScore(t)\n",
    "    print t , ' & ', s[0] , ' & ',s[1],' & ', s[2], '\\\\\\ \\\\hline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad, sad, and rubbish.  &  0.767  &  0.233  &  0.0 \\\\ \\hline\n",
    "great old movie drama.  &  0.0  &  0.423  &  0.577 \\\\ \\hline\n",
    "i always enjoy thomas gomez.  &  0.0  &  0.484  &  0.516 \\\\ \\hline\n",
    "it is a perfect scene.  &  0.0  &  0.448  &  0.552 \\\\ \\hline\n",
    "this film sucks!  &  0.583  &  0.417  &  0.0 \\\\ \\hline\n",
    "the two actors are very natural.  &  0.0  &  0.642  &  0.358 \\\\ \\hline\n",
    "it was hilarious.  &  0.0  &  0.426  &  0.574 \\\\ \\hline\n",
    "it was dumb.  &  0.623  &  0.377  &  0.0 \\\\ \\hline\n",
    "well acted and good enough plot.  &  0.0  &  0.444  &  0.556 \\\\ \\hline\n",
    "it was weak, very very weak.  &  0.592  &  0.408  &  0.0 \\\\ \\hline\n",
    "it' s horrible.  &  0.778  &  0.222  &  0.0 \\\\ \\hline\n",
    "nothing more, nothing less.  &  0.0  &  1.0  &  0.0 \\\\ \\hline\n",
    "she' s a good actress.  &  0.0  &  0.408  &  0.592 \\\\ \\hline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
